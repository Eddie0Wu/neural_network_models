{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational autoencoder in pytorch\n",
    "\n",
    "The following cells contain the codes for building a variational autoencoder in Pytorch, and training it with MNIST dataset, along with some visualisations and analysis. It is recommended to run this in Google Colab as training without GPU will take a really long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the required packages\n",
    "!pip install -q torch torchvision altair matplotlib pandas\n",
    "!git clone -q https://github.com/afspies/icl_dl_cw2_utils\n",
    "from icl_dl_cw2_utils.utils.plotting import plot_tsne\n",
    "%load_ext google.colab.data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive') # Outputs will be saved in google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "if not os.path.exists('/content/drive/MyDrive/VAE/'):\n",
    "    os.makedirs('/content/drive/MyDrive/VAE/')\n",
    "\n",
    "# Set a random seed to ensure that the results are reproducible.\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(0)\n",
    "\n",
    "GPU = True # Choose whether to use GPU\n",
    "if GPU:\n",
    "    device = torch.device(\"cuda\"  if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Hyperparameters \n",
    "num_epochs = 20\n",
    "learning_rate = 0.0005\n",
    "batch_size = 64\n",
    "latent_dim = 24     # Choose a value for the size of the latent space\n",
    "\n",
    "# Additional Hyperparameters \n",
    "hidden_layer = 400\n",
    "\n",
    "# (Optionally) Modify transformations on input\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))\n",
    "# ])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# (Optionally) Modify the network's output for visualizing your images\n",
    "# def denorm(x):\n",
    "#     x = x*0.3081 + 0.1307\n",
    "#     return x\n",
    "\n",
    "def denorm(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_dat = datasets.MNIST(\n",
    "    \"data/\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dat = datasets.MNIST(\"data/\", train=False, transform=transform)\n",
    "\n",
    "loader_train = DataLoader(train_dat, batch_size, shuffle=True)\n",
    "loader_test = DataLoader(test_dat, batch_size, shuffle=False)\n",
    "\n",
    "# Don't change \n",
    "sample_inputs, _ = next(iter(loader_test))\n",
    "fixed_input = sample_inputs[:32, :, :, :]\n",
    "save_image(fixed_input, '/content/drive/MyDrive/VAE/image_original.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VAE\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # self.encoder = nn.Sequential(\n",
    "        #     nn.Conv2d(1, 16, kernel_size = 3),\n",
    "        #     nn.BatchNorm2d(16),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.Conv2d(16, 32, kernel_size = 3),\n",
    "        #     nn.BatchNorm2d(32),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.Conv2d(32, 64, kernel_size = 3, stride = 2),\n",
    "        #     nn.BatchNorm2d(64),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.Conv2d(64, 128, kernel_size = 3, stride = 2),\n",
    "        #     nn.BatchNorm2d(128),\n",
    "        #     nn.LeakyReLU()\n",
    "        # )\n",
    "\n",
    "        # self.fc_mean = nn.Linear(128*5*5, latent_dim)\n",
    "        # self.fc_logvar = nn.Linear(128*5*5, latent_dim)\n",
    "        # self.fc_grow = nn.Linear(latent_dim, 128*5*5)\n",
    "\n",
    "        # self.decoder = nn.Sequential(\n",
    "        #     nn.ConvTranspose2d(128, 64, kernel_size = 3, stride = 2),\n",
    "        #     nn.BatchNorm2d(64),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.ConvTranspose2d(64, 32, kernel_size = 4, stride = 2),\n",
    "        #     nn.BatchNorm2d(32),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.ConvTranspose2d(32, 16, kernel_size = 3),\n",
    "        #     nn.BatchNorm2d(16),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.ConvTranspose2d(16, 1, kernel_size = 3),\n",
    "        #     nn.Sigmoid()\n",
    "        # )\n",
    "        ### I tried implementing convolutional VAE too, but found \n",
    "        ### fully-connected VAE to perform better, hence I chose to \n",
    "        ### stick with fully-connected VAE and commented out the codes\n",
    "        ### for convolutional VAE.\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, hidden_layer),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_layer, 100),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc_mean = nn.Linear(100, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(100, latent_dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, 100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100, hidden_layer),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_layer, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def encode(self, x):\n",
    "\n",
    "        # x = self.encoder(x)\n",
    "        # x = x.view(x.shape[0], -1)\n",
    "        # mu = self.fc_mean(x)\n",
    "        # logvar = self.fc_logvar(x)\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.encoder(x)\n",
    "        mu = self.fc_mean(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "\n",
    "        return mu, logvar\n",
    "    \n",
    "    \n",
    "    def reparametrize(self, mu, logvar):\n",
    "\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "\n",
    "    def decode(self, z):\n",
    "\n",
    "        z = self.decoder(z)\n",
    "        z = z.view(z.shape[0], 1, 28, 28)\n",
    "        return z\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        out = self.decode(z)\n",
    "        return out, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model \n",
    "model = VAE(latent_dim).to(device)\n",
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))\n",
    "print(model)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "def loss_function_VAE(recon_x, x, mu, logvar, beta = 1):\n",
    "        \n",
    "        # mse = nn.MSELoss()\n",
    "        # recon_loss = F.mse_loss(recon_x, x)\n",
    "        # kl_divergence = torch.mean(-0.5*torch.sum(1 + logvar - mu**2 - logvar.exp(), dim = 1), dim = 0)\n",
    "        # loss = recon_loss + beta*kl_divergence\n",
    "\n",
    "        bce = F.binary_cross_entropy(recon_x, x, reduction = 'sum')\n",
    "        kl_divergence = -0.5*torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
    "        loss = bce + beta*kl_divergence\n",
    "        return loss, bce, kl_divergence\n",
    "\n",
    "\n",
    "def test_part(loader, model, beta = 1):\n",
    "        # record the various losses\n",
    "        recon_loss = 0\n",
    "        kl_div = 0\n",
    "        total_loss = 0\n",
    "        count = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "          for x,y in loader:\n",
    "            x = x.to(device = device)\n",
    "            y = y.to(device = device)\n",
    "            # pass input through the model\n",
    "            recon_x, mu, logvar = model(x)\n",
    "            loss, rec_loss, kld = loss_function_VAE(recon_x, x, mu, logvar, beta = beta)\n",
    "            # update the losses\n",
    "            recon_loss += rec_loss\n",
    "            kl_div += kld\n",
    "            total_loss += loss\n",
    "            count += 1\n",
    "          print(f'test loss: {total_loss/count:.5f}')\n",
    "          return (total_loss/count), (recon_loss/count), (kl_div/count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "# for plotting\n",
    "print_every = 200\n",
    "train_losses = []\n",
    "train_recon_losses = []\n",
    "train_klds = []\n",
    "test_losses = []\n",
    "test_recon_losses = []\n",
    "test_klds = []\n",
    "\n",
    "for epoch in range(num_epochs):     \n",
    "\n",
    "        for t, (data, _) in enumerate(loader_train):\n",
    "          model.train()\n",
    "          data = data.to(device = device)\n",
    "          # train the model\n",
    "          recon_x, mu, logvar = model(data)\n",
    "          loss, recon_loss, kld = loss_function_VAE(recon_x, data, mu, logvar, beta = 1)\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          if t%print_every == 0:\n",
    "            print(f'Epoch:{epoch}, Iteration:{t}, Loss = {loss.item():.5f}')\n",
    "            train_losses.append(loss)\n",
    "            train_recon_losses.append(recon_loss)\n",
    "            train_klds.append(kld)\n",
    "            aa,bb,cc  = test_part(loader_test, model, beta = 1)\n",
    "            test_losses.append(aa)\n",
    "            test_recon_losses.append(bb)\n",
    "            test_klds.append(cc)\n",
    "        \n",
    "        # save the model\n",
    "        if epoch == num_epochs - 1:\n",
    "            with torch.no_grad():\n",
    "                torch.jit.save(torch.jit.trace(model, (data), check_trace=False),\n",
    "                    '/content/drive/MyDrive/VAE/VAE_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimenting with other values of beta\n",
    "# codes are the same as the previous cell\n",
    "\n",
    "betaa = 0.4\n",
    "model2 = VAE(latent_dim).to(device)\n",
    "\n",
    "train_losses2 = []\n",
    "train_recon_losses2 = []\n",
    "train_klds2 = []\n",
    "test_losses2 = []\n",
    "test_recon_losses2 = []\n",
    "test_klds2 = []\n",
    "\n",
    "for epoch in range(num_epochs):     \n",
    "        for t, (data, _) in enumerate(loader_train):\n",
    "          model2.train()\n",
    "          data = data.to(device = device)\n",
    "\n",
    "          recon_x, mu, logvar = model(data)\n",
    "          loss, recon_loss, kld = loss_function_VAE(recon_x, data, mu, logvar, beta = betaa)\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          if t%print_every == 0:\n",
    "            print(f'Epoch:{epoch}, Iteration:{t}, Loss = {loss.item():.5f}')\n",
    "            train_losses2.append(loss)\n",
    "            train_recon_losses2.append(recon_loss)\n",
    "            train_klds2.append(kld)\n",
    "            aa,bb,cc  = test_part(loader_test, model, beta = betaa)\n",
    "            test_losses2.append(aa)\n",
    "            test_recon_losses2.append(bb)\n",
    "            test_klds2.append(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting loss\n",
    "# Loss curves with beta = 1\n",
    "iterations = list(range(len(train_losses)))\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.plot(iterations, train_losses, label = \"total_loss\")\n",
    "ax1.plot(iterations, train_recon_losses, label = \"recon_loss\")\n",
    "ax1.plot(iterations, train_klds, label = \"kl_loss\")\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title(\"train, Beta = 1\")\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.plot(iterations, test_losses, label = \"total_loss\")\n",
    "ax2.plot(iterations, test_recon_losses, label = \"recon_loss\")\n",
    "ax2.plot(iterations, test_klds, label = \"kl_loss\")\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title(\"test, Beta = 1\")\n",
    "ax2.legend(loc='best')\n",
    "\n",
    "plt.savefig(\"/content/drive/MyDrive/VAE/loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss curves with beta less than 1\n",
    "# here is an example of a loss plot with beta = 0.4\n",
    "iterations = list(range(len(train_losses2)))\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.plot(iterations, train_losses2, label = \"total_loss\")\n",
    "ax1.plot(iterations, train_recon_losses2, label = \"recon_loss\")\n",
    "ax1.plot(iterations, train_klds2, label = \"kl_loss\")\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title(f\"train, Beta = {betaa}\")\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.plot(iterations, test_losses, label = \"total_loss\")\n",
    "ax2.plot(iterations, test_recon_losses, label = \"recon_loss\")\n",
    "ax2.plot(iterations, test_klds, label = \"kl_loss\")\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title(f\"test, Beta = {betaa}\")\n",
    "ax2.legend(loc='best')\n",
    "\n",
    "plt.savefig(\"/content/drive/MyDrive/VAE/loss_otherbeta4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show samples and reconstruction\n",
    "\n",
    "# Load the model\n",
    "print('Input images')\n",
    "print('-'*50)\n",
    "\n",
    "sample_inputs, _ = next(iter(loader_test))\n",
    "fixed_input = sample_inputs[0:32, :, :, :]\n",
    "\n",
    "# Visualize the original images of the last batch of the test set\n",
    "img = make_grid(denorm(fixed_input), nrow=8, padding=2, normalize=False,\n",
    "                range=None, scale_each=False, pad_value=0)\n",
    "plt.figure()\n",
    "show(img)\n",
    "\n",
    "print('Reconstructed images')\n",
    "print('-'*50)\n",
    "with torch.no_grad():\n",
    "    # visualize the reconstructed images of the last batch of test set    \n",
    "    fixed_input = fixed_input.to(device = device)\n",
    "    recon_batch, mu, logvar = model(fixed_input)\n",
    "    \n",
    "    recon_batch = recon_batch.cpu()\n",
    "    recon_batch = make_grid(denorm(recon_batch), nrow=8, padding=2, normalize=False,\n",
    "                            range=None, scale_each=False, pad_value=0)\n",
    "    plt.figure()\n",
    "    show(recon_batch)\n",
    "\n",
    "print('Generated Images')  \n",
    "print('-'*50)\n",
    "model.eval()\n",
    "n_samples = 256\n",
    "z = torch.randn(n_samples,latent_dim).to(device)\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # z = z.view(-1, 32, latent_dim)\n",
    "    # out = mu + z * torch.exp(0.5*logvar)\n",
    "    # out = out.view(256, -1)\n",
    "    # samples = model.decode(out)\n",
    "\n",
    "    samples = model.decode(z)\n",
    "    \n",
    "    samples = samples.cpu()\n",
    "    samples = make_grid(denorm(samples), nrow=16, padding=2, normalize=False,\n",
    "                            range=None, scale_each=False, pad_value=0)\n",
    "    plt.figure(figsize = (8,8))\n",
    "    show(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation with TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "tsne_loader = DataLoader(test_dat, batch_size = 1, shuffle = False)\n",
    "\n",
    "test_mu = torch.empty(0)\n",
    "label = np.empty(10000)\n",
    "test_mu = test_mu.to(device = device)\n",
    "for i, (x, y) in enumerate(tsne_loader):\n",
    "  x = x.to(device = device)\n",
    "  label[i] = y\n",
    "  # pass input through the model to obtain mu and logvar\n",
    "  mu, logvar = model2.encode(x)\n",
    "  # append mu values to the test_mu tensor\n",
    "  test_mu = torch.cat((test_mu, mu), dim = 0)\n",
    "\n",
    "test_mu = test_mu.detach().to(device = 'cpu').numpy()\n",
    "\n",
    "# use TSNE to create z_embedded\n",
    "z_embedded = TSNE(n_components=2).fit_transform(test_mu)\n",
    "print(z_embedded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dat, 10000, shuffle=False)\n",
    "\"\"\" Inputs to the function are\n",
    "        z_embedded - X, Y positions for every point in test_dataloader\n",
    "        test_dataloader - dataloader with batchsize set to 10000\n",
    "        num_points - number of points plotted (will slow down with >1k)\n",
    "\"\"\"\n",
    "plot_tsne(z_embedded, test_dataloader, num_points=1000, darkmode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Visualizations\n",
    "colors = ['red','purple','blue','orange','yellow','green','black','brown','pink','violet']\n",
    "nums = ['red: 0','purple: 1','blue: 2','orange: 3','yellow: 4','green: 5','black: 6','brown: 7','pink: 8','violet: 9']\n",
    "\n",
    "### the codes below are experimenting with different ways to plot the digits\n",
    "# zz = np.hstack((z_embedded, label.reshape(10000,1)))\n",
    "# zz = zz[zz[:,2].argsort()]\n",
    "# fig = plt.figure(figsize = (8,8))\n",
    "# ax1 = fig.add_subplot(1,1,1)\n",
    "# for i in range(10):\n",
    "#   ax1.scatter(zz[i*1000:i*1000+1000, 0], zz[i*1000:i*1000+1000, 1], c = colors[i], label = i)\n",
    "# ax1.legend(loc='best')\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "# plot the digits using different colours\n",
    "plt.scatter(z_embedded[:,0], z_embedded[:,1], c = label, cmap = ListedColormap(colors))\n",
    "\n",
    "# use colorbar for labelling\n",
    "cb = plt.colorbar()\n",
    "loc = np.arange(0, max(label), max(label)/float(len(colors)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels(nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Visualizations\n",
    "colors = ['red','purple','blue','orange','yellow','green','black','brown','pink','violet']\n",
    "nums = ['red: 0','purple: 1','blue: 2','orange: 3','yellow: 4','green: 5','black: 6','brown: 7','pink: 8','violet: 9']\n",
    "\n",
    "\n",
    "# zz = np.hstack((z_embedded, label.reshape(10000,1)))\n",
    "# zz = zz[zz[:,2].argsort()]\n",
    "# fig = plt.figure(figsize = (8,8))\n",
    "# ax1 = fig.add_subplot(1,1,1)\n",
    "# for i in range(10):\n",
    "#   ax1.scatter(zz[i*1000:i*1000+1000, 0], zz[i*1000:i*1000+1000, 1], c = colors[i], label = i)\n",
    "# ax1.legend(loc='best')\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "plt.scatter(z_embedded[:,0], z_embedded[:,1], c = label, cmap = ListedColormap(colors))\n",
    "\n",
    "cb = plt.colorbar()\n",
    "loc = np.arange(0, max(label), max(label)/float(len(colors)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels(nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolating in the latent space\n",
    "\n",
    "# look through the data to decide what digits to use\n",
    "data = []\n",
    "numbers = []\n",
    "count = 0\n",
    "for i, (x,y) in enumerate(tsne_loader):\n",
    "  count += 1\n",
    "  data.append(x)\n",
    "  numbers.append(y)\n",
    "  if count == 10:\n",
    "    break\n",
    "print(numbers)\n",
    "\n",
    "# position 2 and 3 contain the number 1 and 0, which I will use for this exercise.\n",
    "mu_one, logvar_one = model.encode(data[2].to(device=device))\n",
    "mu_zero, logvar_zero = model.encode(data[3].to(device=device))\n",
    "\n",
    "# linear interpolation with 32 intervals\n",
    "frequency = 32\n",
    "diff = (mu_one - mu_zero) / (frequency - 1)\n",
    "interpolation = torch.empty(0).to(device=device)\n",
    "for i in range(frequency):\n",
    "  interpolation = torch.cat((interpolation, mu_zero + i*diff), dim = 0)\n",
    "\n",
    "out = model.decode(interpolation)\n",
    "\n",
    "# plot the interpolation\n",
    "samples = make_grid(out, nrow=8, padding=2, normalize=False,\n",
    "                            range=None, scale_each=False, pad_value=0)\n",
    "samples = samples.detach().cpu()\n",
    "plt.figure(figsize = (8,8))\n",
    "show(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
