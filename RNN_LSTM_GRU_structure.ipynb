{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network (incl. LSTM and GRU)\n",
    "\n",
    "This notebook contains the codes for building RNN in pytorch. It also includes the structures of LSTM and GRU, as well as they work under the hood. It is recommended to run this in Google Colas as training without GPU will take a really long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"\" # this should change depending on where the data files are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from os import makedirs\n",
    "\n",
    "if not os.path.exists('/content/data_speech_commands_v0.02/'):\n",
    "    os.makedirs('/content/data_speech_commands_v0.02/')\n",
    "\n",
    "if not exists('data_speech_commands_v0.02.zip'):\n",
    "    !wget -O data_speech_commands_v0.02.zip https://www.doc.ic.ac.uk/~pam213/co460_files/data_speech_commands_v0.02.zip\n",
    "\n",
    "!unzip data_speech_commands_v0.02.zip -d \"/content/data_speech_commands_v0.02/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechCommandsDataset(Dataset):\n",
    "    \"\"\"Google Speech Commands dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, split):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the data files.\n",
    "            split    (string): In [\"train\", \"valid\", \"test\"].\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "\n",
    "        self.number_of_classes = len(self.get_classes())\n",
    "\n",
    "        self.class_to_file = defaultdict(list)\n",
    "\n",
    "        self.valid_filenames = self.get_valid_filenames()\n",
    "        self.test_filenames = self.get_test_filenames()\n",
    "\n",
    "        for c in self.get_classes():\n",
    "            file_name_list = sorted(os.listdir(self.root_dir + \"data_speech_commands_v0.02/\" + c))\n",
    "            for filename in file_name_list:\n",
    "                if split == \"train\":\n",
    "                    if (filename not in self.valid_filenames[c]) and (filename not in self.test_filenames[c]):\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                elif split == \"valid\":\n",
    "                    if filename in self.valid_filenames[c]:\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                elif split == \"test\":\n",
    "                    if filename in self.test_filenames[c]:\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid split name.\")\n",
    "\n",
    "        self.filepath_list = list()\n",
    "        self.label_list = list()\n",
    "        for cc, c in enumerate(self.get_classes()):\n",
    "            f_extension = sorted(list(self.class_to_file[c]))\n",
    "            l_extension = [cc for i in f_extension]\n",
    "            f_extension = [self.root_dir + \"data_speech_commands_v0.02/\" + c + \"/\" + filename for filename in f_extension]\n",
    "            self.filepath_list.extend(f_extension)\n",
    "            self.label_list.extend(l_extension)\n",
    "        self.number_of_samples = len(self.filepath_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.number_of_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = np.zeros((16000, ), dtype=np.float32)\n",
    "\n",
    "        sample_file = self.filepath_list[idx]\n",
    "\n",
    "        sample_from_file = read(sample_file)[1]\n",
    "        sample[:sample_from_file.size] = sample_from_file\n",
    "        sample = sample.reshape((16000, ))\n",
    "        \n",
    "        sample = librosa.feature.mfcc(y=sample, sr=16000, hop_length=512, n_fft=2048).transpose().astype(np.float32)\n",
    "\n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "    def get_classes(self):\n",
    "        return ['one', 'two', 'three']\n",
    "\n",
    "    def get_valid_filenames(self):\n",
    "        class_names = self.get_classes()\n",
    "\n",
    "        class_to_filename = defaultdict(set)\n",
    "        with open(self.root_dir + \"data_speech_commands_v0.02/validation_list.txt\", \"r\") as fp:\n",
    "            for line in fp:\n",
    "                clean_line = line.strip().split(\"/\")\n",
    "\n",
    "                if clean_line[0] in class_names:\n",
    "                    class_to_filename[clean_line[0]].add(clean_line[1])\n",
    "\n",
    "        return class_to_filename\n",
    "\n",
    "    def get_test_filenames(self):\n",
    "        class_names = self.get_classes()\n",
    "\n",
    "        class_to_filename = defaultdict(set)\n",
    "        with open(self.root_dir + \"data_speech_commands_v0.02/testing_list.txt\", \"r\") as fp:\n",
    "            for line in fp:\n",
    "                clean_line = line.strip().split(\"/\")\n",
    "\n",
    "                if clean_line[0] in class_names:\n",
    "                    class_to_filename[clean_line[0]].add(clean_line[1])\n",
    "\n",
    "        return class_to_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpeechCommandsDataset(dataset_folder,\n",
    "                                      \"train\")\n",
    "valid_dataset = SpeechCommandsDataset(dataset_folder,\n",
    "                                      \"valid\")\n",
    "\n",
    "test_dataset = SpeechCommandsDataset(dataset_folder,\n",
    "                                     \"test\")\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "valid_every_n_steps = 20\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM and GRU\n",
    "\n",
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "\n",
    "        self.x2h = nn.Linear(input_size, 4*hidden_size, bias = bias)\n",
    "        self.h2h = nn.Linear(hidden_size, 4*hidden_size, bias = bias)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        if hx is None:\n",
    "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
    "            hx = (hx, hx)\n",
    "            \n",
    "        # We used hx to pack both the hidden and cell states\n",
    "        hx, cx = hx\n",
    "\n",
    "        # Linear transformation\n",
    "        combined = self.x2h(input) + self.h2h(hx)\n",
    "\n",
    "        # Non-linearities\n",
    "        gates = torch.sigmoid(combined[ : , : 3*self.hidden_size])\n",
    "        f_t = gates[ : , : self.hidden_size ]\n",
    "        i_t = gates[ : , self.hidden_size : 2*self.hidden_size]\n",
    "        o_t = gates[ : , 2 * self.hidden_size : ]\n",
    "\n",
    "        cell_temp = torch.tanh(combined[ : , 3 * self.hidden_size : ])\n",
    "\n",
    "        # Output\n",
    "        cy = f_t * cx + i_t * cell_temp\n",
    "        hy = o_t * torch.tanh(cy)\n",
    "\n",
    "        return (hy, cy)\n",
    "\n",
    "class BasicRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True, nonlinearity=\"tanh\"):\n",
    "        super(BasicRNNCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.nonlinearity = nonlinearity\n",
    "        if self.nonlinearity not in [\"tanh\", \"relu\"]:\n",
    "            raise ValueError(\"Invalid nonlinearity selected for RNN.\")\n",
    "\n",
    "        self.x2h = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "            \n",
    "    def forward(self, input, hx=None):\n",
    "        if hx is None:\n",
    "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
    "\n",
    "        activation = getattr(nn.functional, self.nonlinearity)\n",
    "        hy = activation(self.x2h(input) + self.h2h(hx))\n",
    "\n",
    "        return hy\n",
    "\n",
    "    \n",
    "    \n",
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "\n",
    "        self.x2h = nn.Linear(input_size, hidden_size, bias = bias)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size, bias = bias)\n",
    "\n",
    "        self.x2r = nn.Linear(input_size, 2*hidden_size, bias = bias)\n",
    "        self.h2r = nn.Linear(hidden_size, 2*hidden_size, bias = bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        if hx is None:\n",
    "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
    "\n",
    "\n",
    "        # Linear transformation\n",
    "        combined = self.x2r(input) + self.h2r(hx)\n",
    "        x_transformed = self.x2h(input)\n",
    "        h_transformed = self.h2h(hx)\n",
    "\n",
    "        # Non-linearities\n",
    "        gates = torch.sigmoid(combined)\n",
    "        r_t = gates[ : , : self.hidden_size]\n",
    "        z_t = gates[ : , self.hidden_size : ]\n",
    "\n",
    "        n_t = torch.tanh(x_transformed + r_t * h_transformed)\n",
    "\n",
    "        # Output\n",
    "        hy = (1-z_t) * n_t + z_t * hx\n",
    "        \n",
    "        return hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RNN models\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, mode, input_size, hidden_size, num_layers, bias, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.rnn_cell_list = nn.ModuleList()\n",
    "        \n",
    "        if mode == 'LSTM':\n",
    "\n",
    "              self.rnn_cell_list.append(LSTMCell(self.input_size,\n",
    "                                                self.hidden_size,\n",
    "                                                self.bias))\n",
    "              \n",
    "              for i in range(1, self.num_layers):\n",
    "                    self.rnn_cell_list.append(LSTMCell(self.hidden_size,\n",
    "                                                      self.hidden_size,\n",
    "                                                      self.bias))\n",
    "\n",
    "\n",
    "        elif mode == 'GRU':\n",
    "    \n",
    "              self.rnn_cell_list.append(GRUCell(self.input_size,\n",
    "                                                self.hidden_size,\n",
    "                                                self.bias))\n",
    "              \n",
    "              for i in range(1, self.num_layers):\n",
    "                    self.rnn_cell_list.append(GRUCell(self.hidden_size,\n",
    "                                                      self.hidden_size,\n",
    "                                                      self.bias))     \n",
    "        \n",
    "\n",
    "        elif mode == 'RNN_TANH':\n",
    "    \n",
    "              self.rnn_cell_list.append(BasicRNNCell(self.input_size,\n",
    "                                                    self.hidden_size,\n",
    "                                                    self.bias,\n",
    "                                                    \"tanh\"))\n",
    "              \n",
    "              for i in range(1, self.num_layers):\n",
    "                    self.rnn_cell_list.append(BasicRNNCell(self.hidden_size,\n",
    "                                                          self.hidden_size,\n",
    "                                                          self.bias,\n",
    "                                                          \"tanh\"))\n",
    "\n",
    "                \n",
    "        elif mode == 'RNN_RELU':\n",
    "        \n",
    "              self.rnn_cell_list.append(BasicRNNCell(self.input_size,\n",
    "                                                    self.hidden_size,\n",
    "                                                    self.bias,\n",
    "                                                    \"relu\"))\n",
    "              \n",
    "              for i in range(1, self.num_layers):\n",
    "                    self.rnn_cell_list.append(BasicRNNCell(self.hidden_size,\n",
    "                                                          self.hidden_size,\n",
    "                                                          self.bias,\n",
    "                                                          \"relu\"))\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid RNN mode selected.\")\n",
    "\n",
    "\n",
    "        # self.att_fc = nn.Linear(self.hidden_size, 1)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "        \n",
    "    def forward(self, input, hx=None):\n",
    "\n",
    "        outs = []\n",
    "        h0 = [None] * self.num_layers if hx is None else list(hx)\n",
    "        \n",
    "        X = list(input.permute(1,0,2))\n",
    "\n",
    "        for j, cell in enumerate(self.rnn_cell_list):\n",
    "\n",
    "              hx_minus_one = h0[j]\n",
    "\n",
    "              for i in range(input.shape[1]):\n",
    "\n",
    "                    hx = cell(X[i], hx_minus_one)\n",
    "                    hx_minus_one = hx\n",
    "                    \n",
    "                    if self.mode == \"LSTM\":\n",
    "                        X[i] = hx[0]\n",
    "                    else:\n",
    "                        X[i] = hx    \n",
    "\n",
    "        outs = X\n",
    "        out = outs[-1].squeeze()\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "class BidirRecurrentModel(nn.Module):\n",
    "    def __init__(self, mode, input_size, hidden_size, num_layers, bias, output_size):\n",
    "        super(BidirRecurrentModel, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.rnn_cell_list = nn.ModuleList()\n",
    "        self.rnn_cell_list_rev = nn.ModuleList()\n",
    "        \n",
    "        if mode == 'LSTM':\n",
    "            self.rnn_cell_list.append(LSTMCell(self.input_size,\n",
    "                                               self.hidden_size,\n",
    "                                               self.bias))\n",
    "        \n",
    "            for i in range(1, self.num_layers):\n",
    "                self.rnn_cell_list.append(LSTMCell(self.hidden_size,\n",
    "                                                   self.hidden_size,\n",
    "                                                   self.bias))\n",
    "\n",
    "            self.rnn_cell_list_rev.append(LSTMCell(self.input_size,\n",
    "                                                   self.hidden_size,\n",
    "                                                   self.bias))\n",
    "        \n",
    "            for i in range(1, self.num_layers):\n",
    "                self.rnn_cell_list_rev.append(LSTMCell(self.hidden_size,\n",
    "                                                       self.hidden_size,\n",
    "                                                       self.bias))\n",
    "\n",
    "\n",
    "\n",
    "        elif mode == 'GRU':\n",
    "            self.rnn_cell_list.append(GRUCell(self.input_size,\n",
    "                                              self.hidden_size,\n",
    "                                              self.bias))\n",
    "        \n",
    "            for i in range(1, self.num_layers):\n",
    "                self.rnn_cell_list.append(GRUCell(self.hidden_size,\n",
    "                                                  self.hidden_size,\n",
    "                                                  self.bias))\n",
    "\n",
    "            self.rnn_cell_list_rev.append(GRUCell(self.input_size,\n",
    "                                                   self.hidden_size,\n",
    "                                                   self.bias))\n",
    "        \n",
    "            for i in range(1, self.num_layers):\n",
    "                self.rnn_cell_list_rev.append(GRUCell(self.hidden_size,\n",
    "                                                      self.hidden_size,\n",
    "                                                      self.bias))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        elif mode == 'RNN_TANH':\n",
    "            self.rnn_cell_list.append(BasicRNNCell(self.input_size,\n",
    "                                                   self.hidden_size,\n",
    "                                                   self.bias,\n",
    "                                                   \"tanh\"))\n",
    "        \n",
    "            for i in range(1, self.num_layers):\n",
    "                self.rnn_cell_list.append(BasicRNNCell(self.hidden_size,\n",
    "                                                       self.hidden_size,\n",
    "                                                       self.bias,\n",
    "                                                       \"tanh\"))\n",
    "\n",
    "            self.rnn_cell_list_rev.append(BasicRNNCell(self.input_size,\n",
    "                                                       self.hidden_size,\n",
    "                                                       self.bias,\n",
    "                                                       \"tanh\"))\n",
    "        \n",
    "            for i in range(1, self.num_layers):\n",
    "                self.rnn_cell_list_rev.append(BasicRNNCell(self.hidden_size,\n",
    "                                                           self.hidden_size,\n",
    "                                                           self.bias,\n",
    "                                                           \"tanh\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        elif mode == 'RNN_RELU':\n",
    "            self.rnn_cell_list.append(BasicRNNCell(self.input_size,\n",
    "                                                   self.hidden_size,\n",
    "                                                   self.bias,\n",
    "                                                   \"relu\"))\n",
    "        \n",
    "            for i in range(1, self.num_layers):\n",
    "                self.rnn_cell_list.append(BasicRNNCell(self.hidden_size,\n",
    "                                                       self.hidden_size,\n",
    "                                                       self.bias,\n",
    "                                                       \"relu\"))\n",
    "\n",
    "            self.rnn_cell_list_rev.append(BasicRNNCell(self.input_size,\n",
    "                                                       self.hidden_size,\n",
    "                                                       self.bias,\n",
    "                                                       \"relu\"))\n",
    "            \n",
    "            for i in range(1, self.num_layers):\n",
    "                self.rnn_cell_list_rev.append(BasicRNNCell(self.hidden_size,\n",
    "                                                           self.hidden_size,\n",
    "                                                           self.bias,\n",
    "                                                           \"relu\"))\n",
    "            \n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid RNN mode selected.\")\n",
    "\n",
    "          \n",
    "        self.fc = nn.Linear(self.hidden_size*2, self.output_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, input, hx=None):\n",
    "        \n",
    "        # Forward processing\n",
    "        outs = []\n",
    "        h0 = [None] * self.num_layers * 2 if hx is None else list(hx)\n",
    "        X = list(input.permute(1,0,2))\n",
    "\n",
    "        for j, cell in enumerate(self.rnn_cell_list):\n",
    "\n",
    "              hx_minus_one = h0[j]\n",
    "\n",
    "              for i in range(input.shape[1]):\n",
    "\n",
    "                    hx = cell(X[i], hx_minus_one)\n",
    "                    hx_minus_one = hx\n",
    "                    if self.mode == \"LSTM\":\n",
    "                        X[i] = hx[0]\n",
    "                    else:\n",
    "                        X[i] = hx    \n",
    "\n",
    "        outs = X\n",
    "    \n",
    "\n",
    "        # Reverse processing\n",
    "        outs_rev = []\n",
    "        X = list(input.permute(1,0,2))\n",
    "        X.reverse()\n",
    "\n",
    "        for j, cell in enumerate(self.rnn_cell_list_rev):\n",
    "\n",
    "              hx_minus_one = h0[j + self.num_layers]\n",
    "\n",
    "              for i in range(input.shape[1]):\n",
    "\n",
    "                    hx = cell(X[i], hx_minus_one)\n",
    "                    hx_minus_one = hx\n",
    "                    if self.mode == \"LSTM\":\n",
    "                        X[i] = hx[0]\n",
    "                    else:\n",
    "                        X[i] = hx    \n",
    "\n",
    "        outs_rev = X\n",
    "\n",
    "        out = outs[-1].squeeze()\n",
    "        out_rev = outs_rev[0].squeeze()\n",
    "        out = torch.cat((out, out_rev), 1)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "seq_dim, input_dim = train_dataset[0][0].shape\n",
    "output_dim = 3\n",
    "\n",
    "hidden_dim = 32\n",
    "# hidden_dim = 48\n",
    "layer_dim = 2\n",
    "bias = True\n",
    "\n",
    "### Change the code below to try running different models:\n",
    "# model = RNNModel(\"RNN_RELU\", input_dim, hidden_dim, layer_dim, bias, output_dim)\n",
    "model = BidirRecurrentModel(\"LSTM\", input_dim, hidden_dim, layer_dim, bias, output_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_list = []\n",
    "iter = 0\n",
    "max_v_accuracy = 0\n",
    "reported_t_accuracy = 0\n",
    "max_t_accuracy = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (audio, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(audio)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            loss.cuda()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        iter += 1\n",
    "\n",
    "        if iter % valid_every_n_steps == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for audio, labels in valid_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
    "                else:\n",
    "                    audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
    "\n",
    "                outputs = model(audio)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            v_accuracy = 100 * correct // total\n",
    "            \n",
    "            is_best = False\n",
    "            if v_accuracy >= max_v_accuracy:\n",
    "                max_v_accuracy = v_accuracy\n",
    "                is_best = True\n",
    "\n",
    "            if is_best:\n",
    "                for audio, labels in test_loader:\n",
    "                    if torch.cuda.is_available():\n",
    "                        audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
    "                    else:\n",
    "                        audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
    "\n",
    "                    outputs = model(audio)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                    total += labels.size(0)\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                    else:\n",
    "                        correct += (predicted == labels).sum()\n",
    "\n",
    "                t_accuracy = 100 * correct // total\n",
    "                reported_t_accuracy = t_accuracy\n",
    "\n",
    "            print('Iteration: {}. Loss: {}. V-Accuracy: {}  T-Accuracy: {}'.format(iter, loss.item(), v_accuracy, reported_t_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
